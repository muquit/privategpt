# Custom Prompts

Custom prompts are powerful tools that shape how Large Language Models (LLMs)
respond to questions. Think of prompts as instructions to the AI - they 
control the style, format, language, and depth of the answers. For example,
you can make the AI explain things like a teacher, write code like a 
developer, or troubleshoot like a system administrator.

This section provides different prompt examples that you can use with 
**privategpt**.  Whether you need responses in specific languages, 
technical documentation, code examples, or structured analysis, these 
prompts will help you get the exact type of response you want from your 
LLM.


## Basic Usage

The prompts help control how the LLM responds to questions. You can 
customize aspects like:
- Response language (English, German, Vietnamese, Bangla etc.)
- Response structure (free-form, bullet points, sections)
- Technical detail level
- Special instructions (like code examples, troubleshooting steps)

Make sure your LLM supports the target language before using language-specific
prompts. The quality of translations might vary depending on the model 
used. Please look at [Ollama Model Libary](https://ollama.com/library)
for finding better multilingual models.

Please define your custom prompt with variable **CUSTOM_PROMPT** in
[Configuration file](#configuration-file)

## Example Prompt Templates

### Default Simple Prompt

This is the basic prompt template that works for most cases:
```python
CUSTOM_PROMT = """
Given the following context, answer the question using only the provided
information. If the answer isn't found in the context, respond with
'I cannot answer this based on the provided context.'

Context:
{context}

Question: {question}

Answer: Let me analyze the context and provide a detailed response.
"""
```

### No BS strict prompt
```python
CUSTOM_PROMPT = """
Use the following context to answer the given question. Be direct and concise.

Rules:
1. Only use information from the provided context
2. For factual questions, provide direct answers without analysis
3. For complex questions, structure your response clearly
4. If the answer isn't in the context, respond with "I cannot answer this based on the provided context"
5. Don't include phrases like "According to the context" or "Based on the provided information"
6. Don't speculate or infer beyond what's directly stated

Context:
{context}

Question: {question}

Answer:"""
```

### Language-Specific Prompts
These prompts tell the LLM to respond in specific languages.


#### German Response
```python
CUSTOM_PROMPT = """Use the following pieces of context to answer the question.
IMPORTANT: Provide your answer in German language only.

Context:
{context}

Question: {question}

Please provide a helpful answer in German:"""
```

#### Vietnamese Response

[Bug #1](../../issues/1)

```python
CUSTOM_PROMPT = """Sử dụng các thông tin ngữ cảnh sau đây để trả lời câu hỏi.
QUAN TRỌNG: Chỉ trả lời bằng tiếng Việt.

Ngữ cảnh:
{context}

Câu hỏi: {question}

Vui lòng cung cấp câu trả lời hữu ích bằng tiếng Việt:"""
```

#### Bangla Response
Using native Bengali script for better accessibility:
```python
CUSTOM_PROMPT = """এই তথ্যগুলো দেখে প্রশ্নের উত্তর দাও।
জরুরি কথা: শুধু বাংলায় উত্তর দিতে হবে।

তথ্য:
{context}

প্রশ্ন: {question}

দয়া করে বাংলায় উত্তর দাও:"""
```

### Technical Documentation Prompts

#### API Documentation
Useful for explaining APIs and their usage:
```python
CUSTOM_PROMPT = """Using the provided context, explain the API usage.
Include examples of common use cases and parameter descriptions.

Context:
{context}

Question: {question}

API Documentation:
1. Overview:
2. Parameters:
3. Usage Examples:
4. Common Patterns:
5. Notes:"""
```

#### Troubleshooting Guide
Helps in diagnosing and solving issues:
```python
CUSTOM_PROMPT = """Using the context provided, help diagnose or solve the issue.
If the exact solution isn't in the context, suggest the most relevant troubleshooting steps.

Context:
{context}

Question: {question}

Analysis and Solution:
1. Problem identification:
2. Relevant context:
3. Solution/Workaround:
4. Prevention tips (if applicable):"""
```

#### Code Examples
Focuses on code explanation with comments:
```python
CUSTOM_PROMPT = """Based on the context, provide an explanation with emphasis on code examples.
Format any code snippets clearly and include comments for better understanding.

Context:
{context}

Question: {question}

Explanation and Code Examples:"""
```

The prompt examples are generated by Claude AI.

## Note

### Language Support
Make sure your LLM supports the target language before using language-specific prompts.
The quality of translations might vary depending on the model used.

### Customizing Prompts
Feel free to mix elements from different prompts to create your own.
Some key points to consider:
- Keep instructions clear and specific
- Include any formatting preferences
- Specify the desired language if needed
- Add structure hints if you want organized responses

### Testing Your Prompts
Always test new prompts with various types of:
- Questions (simple, complex, technical)
- Contexts (short, long, mixed languages)
- Response requirements (code, explanations, troubleshooting)

